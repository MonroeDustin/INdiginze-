{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, json\n",
    "from collections import Counter, OrderedDict\n",
    "import itertools\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basic_features(df):\n",
    "    \"\"\"Compute basic features.\"\"\"\n",
    "\n",
    "    df['f_nchars'] = df['__TEXT__'].map(len)\n",
    "    df['f_nwords'] = df['word'].map(len)\n",
    "\n",
    "    punct_counter = lambda s: sum(1 for c in s\n",
    "                                  if (not c.isalnum())\n",
    "                                      and not c in\n",
    "                                        [\" \", \"\\t\"])\n",
    "    df['f_npunct'] = df['__TEXT__'].map(punct_counter)\n",
    "    df['f_rpunct'] = df['f_npunct'] / df['f_nchars']\n",
    "\n",
    "    df['f_ndigit'] = df['__TEXT__'].map(lambda s: sum(1 for c in s\n",
    "                                  if c.isdigit()))\n",
    "    df['f_rdigit'] = df['f_ndigit'] / df['f_nchars']\n",
    "\n",
    "    upper_counter = lambda s: sum(1 for c in s if c.isupper())\n",
    "    df['f_nupper'] = df['__TEXT__'].map(upper_counter)\n",
    "    df['f_rupper'] = df['f_nupper'] / df['f_nchars']\n",
    "\n",
    "    # fraction named entities recognized (ner) -- 'O' is not recognized\n",
    "    df['f_nner'] = df['ner'].map(lambda ts: sum(1 for t in ts\n",
    "                                              if t != 'O'))\n",
    "    df['f_rner'] = df['f_nner'] / df['f_nwords']\n",
    "\n",
    "    # Check standard sentence pattern:\n",
    "    # if starts with capital, ends with .?!\n",
    "    def check_sentence_pattern(s):\n",
    "        ss = s.strip(r\"\"\"`\"'\"\"\").strip()\n",
    "        return s[0].isupper() and (s[-1] in '.?!\\n')\n",
    "    df['f_sentence_pattern'] = df['__TEXT__'].map(check_sentence_pattern)\n",
    "\n",
    "    # Normalize any LM features\n",
    "    # by dividing logscore by number of words\n",
    "    lm_cols = {c:re.sub(\"_lmscore_\", \"_lmscore_norm_\",c)\n",
    "               for c in df.columns if c.startswith(\"f_lmscore\")}\n",
    "    for c,cnew in lm_cols.items():\n",
    "        df[cnew] = df[c] / df['f_nwords']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|Mt)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "digits = \"([0-9])\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov|me|edu)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"...\" in text: text = text.replace(\"...\",\"<prd><prd><prd>\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    #text = text.replace(\"  \",\" <stop>\") #1\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "I hate wet and reiny days.  It rained a lot in 1816.... a lot - like everyday; there weather in Europe was abnormally wet because it rained in Switzerland on 130 out of the 183 days from April to September. If I was Mary Shelley I might decide to write a book too. Afterall, it was the onnly thing you could do without TV or anything. She said that she \"passed the summer of 1816 in the environs of Geneva...we occasionally amused ourselves with some German stories of ghosts... These tales excited in us a playful desire of imitation\"  So, people were stuck inside and bored. Mary Shelley decided to write a book becuase it was so awful outside. I can totally see her point, you know? I guess I would write a novel if there was nothing else to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please paste your paragraph here: I hate wet and reiny days.  It rained a lot in 1816.... a lot - like everyday; there weather in Europe was abnormally wet because it rained in Switzerland on 130 out of the 183 days from April to September. If I was Mary Shelley I might decide to write a book too. Afterall, it was the onnly thing you could do without TV or anything. She said that she \"passed the summer of 1816 in the environs of Geneva...we occasionally amused ourselves with some German stories of ghosts... These tales excited in us a playful desire of imitation\"  So, people were stuck inside and bored. Mary Shelley decided to write a book becuase it was so awful outside. I can totally see her point, you know? I guess I would write a novel if there was nothing else to do.\n"
     ]
    }
   ],
   "source": [
    "input_string = input(\"Please paste your paragraph here: \")\n",
    "newtext = split_into_sentences(input_string) \n",
    "#pp(newtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm # or en_core_web_lg if need tokenization.\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for idx,text in enumerate(newtext):\n",
    "    doc = nlp(text)\n",
    "    row = {\"__TEXT__\": text}\n",
    "    row['ner'] = [i.pos_ for i in doc]\n",
    "    row['sentiment'] = doc.sentiment\n",
    "    row['word'] = [i.text for i in doc]\n",
    "    data.append(row)\n",
    "    \n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaiah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  import sys\n",
      "C:\\Users\\Isaiah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  \n",
      "C:\\Users\\Isaiah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "C:\\Users\\Isaiah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
     ]
    }
   ],
   "source": [
    "df = make_basic_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = {}\n",
    "dirty = {}\n",
    "bad = 0\n",
    "for idx,row in df.iterrows():\n",
    "    if row['f_sentence_pattern'] and (row['f_npunct'] + row['f_nwords']) > 5 and row['f_nner'] > 0:\n",
    "        cleaned[idx] = row['__TEXT__']\n",
    "    else:\n",
    "        dirty[idx] = row['__TEXT__']\n",
    "        bad += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'I hate wet and reiny days.',\n",
      " 1: 'It rained a lot in 1816....',\n",
      " 3: 'If I was Mary Shelley I might decide to write a book too.',\n",
      " 4: 'Afterall, it was the onnly thing you could do without TV or anything.',\n",
      " 5: 'She said that she \"passed the summer of 1816 in the environs of '\n",
      "    'Geneva...we occasionally amused ourselves with some German stories of '\n",
      "    'ghosts... These tales excited in us a playful desire of imitation\"  So, '\n",
      "    'people were stuck inside and bored.',\n",
      " 6: 'Mary Shelley decided to write a book becuase it was so awful outside.',\n",
      " 7: 'I can totally see her point, you know?',\n",
      " 8: 'I guess I would write a novel if there was nothing else to do.'}\n"
     ]
    }
   ],
   "source": [
    "pp(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'a lot - like everyday; there weather in Europe was abnormally wet because '\n",
      "    'it rained in Switzerland on 130 out of the 183 days from April to '\n",
      "    'September.'}\n"
     ]
    }
   ],
   "source": [
    "pp(dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a lot - like everyday; there weather in Europe was abnormally wet because it '\n",
      " 'rained in Switzerland on 130 out of the 183 days from April to September.']\n"
     ]
    }
   ],
   "source": [
    "dirty_list=list(dirty.values())\n",
    "pp(dirty_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I hate wet and reiny days.',\n",
      " 'It rained a lot in 1816....',\n",
      " 'If I was Mary Shelley I might decide to write a book too.',\n",
      " 'Afterall, it was the onnly thing you could do without TV or anything.',\n",
      " 'She said that she \"passed the summer of 1816 in the environs of Geneva...we '\n",
      " 'occasionally amused ourselves with some German stories of ghosts... These '\n",
      " 'tales excited in us a playful desire of imitation\"  So, people were stuck '\n",
      " 'inside and bored.',\n",
      " 'Mary Shelley decided to write a book becuase it was so awful outside.',\n",
      " 'I can totally see her point, you know?',\n",
      " 'I guess I would write a novel if there was nothing else to do.']\n"
     ]
    }
   ],
   "source": [
    "clean_list=list(cleaned.values())\n",
    "pp(clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converttostr(input_seq, seperator):\n",
    "   # Join all the strings in list\n",
    "   final_str = seperator.join(input_seq)\n",
    "   return final_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperator = ' '\n",
    "df2 = (converttostr(clean_list, seperator))\n",
    "df3 = df2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'onnly', 'reiny', 'afterall', 'becuase'}\n",
      "corrected: only\n",
      "corrected: reins\n",
      "corrected: after all\n",
      "corrected: because\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "text = df2.lower()\n",
    "#splitwords = spell.split_words(\"what was the natureq of your relationshop with the candidate?  what was their title?  What was your role and titlem?\")\n",
    "splitwords = spell.split_words(text)\n",
    "newlist = list(splitwords)\n",
    "misspelled = spell.unknown(newlist)\n",
    "print(misspelled)\n",
    "for word in misspelled:\n",
    "    # Get the one most likely answer\n",
    "    print(\"corrected: \" + spell.correction(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(set): \n",
    "    return list(set) \n",
    "misspelled1 = (convert(misspelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperator = \"\"\n",
    "paragraph = (converttostr(clean_list, seperator))\n",
    "d = split_into_sentences(paragraph)\n",
    "#type(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I hate wet and reiny days.',\n",
       " 'Afterall, it was the onnly thing you could do without TV or anything.',\n",
       " 'Mary Shelley decided to write a book becuase it was so awful outside.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "bad = frozenset(map(str.lower, (misspelled1)))\n",
    "words = lambda sentence: (m.group() for m in re.finditer('\\w+', sentence))\n",
    "data = []\n",
    "for index, sentence in enumerate(d):\n",
    "    if frozenset(words(sentence.lower())) & bad:\n",
    "        data.append(sentence)\n",
    "            #write to a dictonary \n",
    "\n",
    "#words = lambda sentence: (m.group() for m in re.finditer('\\w+', sentence))\n",
    "\n",
    "res = [] \n",
    "for i in data: \n",
    "    if i not in res: \n",
    "        res.append(i) \n",
    "        \n",
    "res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a lot - like everyday; there weather in Europe was abnormally wet because it rained in Switzerland on 130 out of the 183 days from April to September.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seperator = ' '\n",
    "dirt = (converttostr(dirty_list, seperator)) \n",
    "dirt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I hate wet and reiny days.',\n",
       " 'Afterall, it was the onnly thing you could do without TV or anything.',\n",
       " 'Mary Shelley decided to write a book becuase it was so awful outside.',\n",
       " 'a lot - like everyday; there weather in Europe was abnormally wet because it rained in Switzerland on 130 out of the 183 days from April to September.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res += [dirt] \n",
    "res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sentence = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I hate wet and reiny days.',\n",
       " 'Afterall, it was the onnly thing you could do without TV or anything.',\n",
       " 'Mary Shelley decided to write a book becuase it was so awful outside.',\n",
       " 'a lot - like everyday; there weather in Europe was abnormally wet because it rained in Switzerland on 130 out of the 183 days from April to September.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import pylanguagetool\n",
    "\n",
    "def wordcheck():\n",
    "    while True:\n",
    "        sentence = input('enter sentence, type end to exit word checker>')\n",
    "        #sentence = bad_sentence\n",
    "        res = pylanguagetool.api.check(sentence,\"https://languagetool.org/api/v2/\", lang ='en-US')\n",
    "        for match in res['matches']:\n",
    "            print(match['message'],match['replacements'])\n",
    "        if sentence ==\"end\":\n",
    "            break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#wordcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence does not start with an uppercase letter [{'value': 'A'}]\n",
      "Consider using an m-dash if you do not want to join two words. [{'value': '—'}]\n",
      "'Everyday' is an adjective. Did you mean \"every day\"? [{'value': 'every day'}]\n"
     ]
    }
   ],
   "source": [
    "sentence = bad_sentence\n",
    "res = pylanguagetool.api.check(sentence,\"https://languagetool.org/api/v2/\", lang ='en-US')\n",
    "for match in res['matches']:\n",
    "    print(match['message'],match['replacements'])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence does not start with an uppercase letter [{'value': 'A'}]\n",
      "Consider using an m-dash if you do not want to join two words. [{'value': '—'}]\n",
      "'Everyday' is an adjective. Did you mean \"every day\"? [{'value': 'every day'}]\n",
      "Statistics suggests that 'their' (as in 'It’s not their fault.') might be the correct word here, not 'there' (as in 'Is there an answer?'). Please check. [{'value': 'their', 'shortDescription': \"as in 'It’s not their fault.'\"}]\n",
      "{'onnly', 'reiny', 'afterall', 'becuase'}\n",
      "corrected: only\n",
      "corrected: reins\n",
      "corrected: after all\n",
      "corrected: because\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pylanguagetool\n",
    "\n",
    "def wordcheck():\n",
    "    while True:\n",
    "        #sentence = input('enter sentence, type end to exit word checker>')\n",
    "        sentence = bad_sentence\n",
    "        res = pylanguagetool.api.check(sentence,\"https://languagetool.org/api/v2/\", lang ='en-US')\n",
    "        for match in res['matches']:\n",
    "            print(match['message'],match['replacements'])\n",
    "        if res != '':\n",
    "            break\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    wordcheck()\n",
    "    \n",
    "print(misspelled)\n",
    "for word in misspelled:\n",
    "    # Get the one most likely answer\n",
    "    print(\"corrected: \" + spell.correction(word))    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
